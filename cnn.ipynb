{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f0e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb479be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self,input_channel, height, width, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            #Block 1 \n",
    "            nn.Conv2d(input_channel,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            #Block 2\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            #Block 3 \n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            test = torch.randn(1,input_channel,height,width)\n",
    "            output = self.features(test)\n",
    "            flatten_size = output.view(1, -1).shape[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flatten_size,embedding_dim),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "    def forward (self,x):\n",
    "        out = self.features(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f57e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self, input_channel, height, width, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channel,32,kernel_size=3, stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        with torch.no_grad():\n",
    "            test = torch.randn(1,input_channel,height,width)\n",
    "            out = self.pool1(self.act1(self.conv1(test)))\n",
    "            out = self.pool2(self.act2(self.conv2(out)))\n",
    "            out = self.pool3(self.act3(self.conv3(out)))\n",
    "            flaten_size = out.view(1, -1).shape[1]\n",
    "        self.fl = nn.Flatten()\n",
    "        self.ln = nn.Linear(flaten_size,256)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.ln2 = nn.Linear(256,embedding_dim)\n",
    "    def forward(self,x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = self.pool3(self.act3(self.conv3(out)))\n",
    "        out = self.fl(out)\n",
    "        out = self.ln(out)\n",
    "        out = self.act4(out)\n",
    "        out = self.ln2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2573f99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: tensor([[0.1319, 0.0000, 0.0000, 0.0000, 0.0000, 0.0659, 0.0000, 0.1941, 0.0000,\n",
      "         0.0000, 0.0965, 0.0613, 0.0000, 0.0000, 0.0000, 0.0000, 0.0949, 0.0000,\n",
      "         0.0160, 0.0000, 0.0000, 0.1027, 0.1919, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1687, 0.0000, 0.0737, 0.0000, 0.1156, 0.0000, 0.0000, 0.1841, 0.0000,\n",
      "         0.0000, 0.0909, 0.0000, 0.0000, 0.0000, 0.0000, 0.0741, 0.0000, 0.0366,\n",
      "         0.1921, 0.0053, 0.0272, 0.0223, 0.1074, 0.0000, 0.0000, 0.0185, 0.0000,\n",
      "         0.0239, 0.0000, 0.0000, 0.0456, 0.1598, 0.0000, 0.0000, 0.0000, 0.1913,\n",
      "         0.2194, 0.0000, 0.0009, 0.0479, 0.1017, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2490, 0.0344, 0.0000, 0.0000, 0.0967, 0.0266, 0.0390, 0.0125, 0.0535,\n",
      "         0.0000, 0.0000, 0.0320, 0.0000, 0.1389, 0.0312, 0.0000, 0.0521, 0.0758,\n",
      "         0.0317, 0.0661, 0.0576, 0.2269, 0.0979, 0.0477, 0.1148, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0246, 0.0000, 0.0000, 0.0997, 0.0000, 0.0333, 0.0500,\n",
      "         0.0981, 0.3344, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0906, 0.0000, 0.0454, 0.0000, 0.2234, 0.1236, 0.1145, 0.0000, 0.0566,\n",
      "         0.0000, 0.1613, 0.1277, 0.0840, 0.0000, 0.0000, 0.0318, 0.0000, 0.0000,\n",
      "         0.0967, 0.0000, 0.0000, 0.0375, 0.0000, 0.1150, 0.0082, 0.1292, 0.0000,\n",
      "         0.0706, 0.0000, 0.0000, 0.1713, 0.0848, 0.1198, 0.0168, 0.0777, 0.1156,\n",
      "         0.0802, 0.1304, 0.1473, 0.2040, 0.0608, 0.0000, 0.0568, 0.0000, 0.1659,\n",
      "         0.0283, 0.0883, 0.0000, 0.0955, 0.0000, 0.2391, 0.0000, 0.0000, 0.1192,\n",
      "         0.1322, 0.0000, 0.0000, 0.0037, 0.0000, 0.0000, 0.0736, 0.0971, 0.0466,\n",
      "         0.0000, 0.1329, 0.1027, 0.0998, 0.0000, 0.0000, 0.0000, 0.0056, 0.0000,\n",
      "         0.2796, 0.0067, 0.0000, 0.0000, 0.0289, 0.0000, 0.1688, 0.0000, 0.0356,\n",
      "         0.0000, 0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0309, 0.2358, 0.0000,\n",
      "         0.0000, 0.1001, 0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.1145, 0.0000,\n",
      "         0.0272, 0.0000, 0.0000, 0.0972, 0.0837, 0.0000, 0.0000, 0.0003, 0.1212,\n",
      "         0.0350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0061, 0.1432, 0.2377, 0.0000,\n",
      "         0.0000, 0.0000, 0.1066, 0.0801, 0.0000, 0.1169, 0.0194, 0.0000, 0.0680,\n",
      "         0.0000, 0.0398, 0.1933, 0.1968, 0.0614, 0.0000, 0.0536, 0.1201, 0.0000,\n",
      "         0.0000, 0.0039, 0.0000, 0.0000],\n",
      "        [0.1631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0903, 0.0000, 0.1788, 0.0000,\n",
      "         0.0000, 0.0340, 0.0887, 0.0000, 0.0000, 0.0000, 0.0355, 0.0788, 0.0000,\n",
      "         0.0239, 0.0000, 0.0000, 0.0738, 0.1356, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1316, 0.0000, 0.0769, 0.0000, 0.1066, 0.0000, 0.0000, 0.1179, 0.0000,\n",
      "         0.0000, 0.0615, 0.0000, 0.0000, 0.0000, 0.0000, 0.0459, 0.0000, 0.0147,\n",
      "         0.1650, 0.0000, 0.0186, 0.0000, 0.0820, 0.0000, 0.0000, 0.0128, 0.0000,\n",
      "         0.0643, 0.0101, 0.0000, 0.0317, 0.1810, 0.0000, 0.0000, 0.0000, 0.1999,\n",
      "         0.1688, 0.0000, 0.0000, 0.0000, 0.1113, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2555, 0.0774, 0.0000, 0.0000, 0.1291, 0.0000, 0.0931, 0.0662, 0.0629,\n",
      "         0.0000, 0.0000, 0.0225, 0.0000, 0.0703, 0.0660, 0.0000, 0.0153, 0.0544,\n",
      "         0.0000, 0.0320, 0.1072, 0.2137, 0.1233, 0.0717, 0.0911, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0953, 0.0000, 0.0370, 0.0260,\n",
      "         0.1810, 0.3221, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0278,\n",
      "         0.0617, 0.0000, 0.0521, 0.0000, 0.2195, 0.1595, 0.0695, 0.0000, 0.0504,\n",
      "         0.0000, 0.1614, 0.0986, 0.1033, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0982, 0.0000, 0.0000, 0.0456, 0.0000, 0.0734, 0.0601, 0.1514, 0.0000,\n",
      "         0.0440, 0.0340, 0.0000, 0.1622, 0.0773, 0.1249, 0.0394, 0.0905, 0.0877,\n",
      "         0.0992, 0.1062, 0.1857, 0.2280, 0.0388, 0.0000, 0.0397, 0.0000, 0.1789,\n",
      "         0.0851, 0.0900, 0.0000, 0.0745, 0.0000, 0.1804, 0.0000, 0.0000, 0.1534,\n",
      "         0.1254, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0170, 0.1007, 0.0000,\n",
      "         0.0000, 0.1412, 0.1372, 0.0623, 0.0000, 0.0000, 0.0000, 0.0043, 0.0000,\n",
      "         0.2481, 0.0181, 0.0000, 0.0000, 0.0246, 0.0000, 0.2166, 0.0000, 0.0699,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0400, 0.2278, 0.0000,\n",
      "         0.0000, 0.0864, 0.0000, 0.0000, 0.0547, 0.0000, 0.0000, 0.1718, 0.0000,\n",
      "         0.0241, 0.0000, 0.0000, 0.1086, 0.0862, 0.0000, 0.0000, 0.0595, 0.1178,\n",
      "         0.0146, 0.0000, 0.0000, 0.0000, 0.0000, 0.0404, 0.1260, 0.2162, 0.0000,\n",
      "         0.0000, 0.0000, 0.1132, 0.1339, 0.0000, 0.0831, 0.0000, 0.0000, 0.0048,\n",
      "         0.0000, 0.0637, 0.1864, 0.2422, 0.0000, 0.0000, 0.1217, 0.0468, 0.0000,\n",
      "         0.0000, 0.0261, 0.0000, 0.0000],\n",
      "        [0.1504, 0.0000, 0.0000, 0.0000, 0.0000, 0.0335, 0.0000, 0.2090, 0.0000,\n",
      "         0.0000, 0.0848, 0.0952, 0.0000, 0.0000, 0.0000, 0.0000, 0.0880, 0.0000,\n",
      "         0.0199, 0.0000, 0.0000, 0.1130, 0.1829, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1264, 0.0000, 0.0343, 0.0000, 0.1436, 0.0000, 0.0000, 0.1752, 0.0000,\n",
      "         0.0000, 0.0537, 0.0000, 0.0000, 0.0031, 0.0000, 0.0176, 0.0000, 0.0000,\n",
      "         0.2079, 0.0000, 0.0035, 0.0000, 0.0232, 0.0000, 0.0000, 0.0392, 0.0142,\n",
      "         0.0000, 0.0000, 0.0186, 0.0350, 0.2059, 0.0224, 0.0000, 0.0000, 0.2061,\n",
      "         0.1629, 0.0000, 0.0167, 0.0000, 0.0686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2061, 0.0750, 0.0000, 0.0000, 0.1563, 0.0044, 0.0609, 0.0746, 0.0860,\n",
      "         0.0000, 0.0000, 0.0249, 0.0000, 0.0765, 0.0271, 0.0000, 0.0000, 0.1013,\n",
      "         0.0251, 0.0388, 0.0996, 0.2342, 0.0715, 0.0000, 0.1197, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0886, 0.0000, 0.0343, 0.0090,\n",
      "         0.1726, 0.3279, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0250,\n",
      "         0.0775, 0.0000, 0.0000, 0.0000, 0.1806, 0.1453, 0.0531, 0.0000, 0.0054,\n",
      "         0.0000, 0.1495, 0.1398, 0.0889, 0.0000, 0.0000, 0.0144, 0.0000, 0.0000,\n",
      "         0.0622, 0.0000, 0.0000, 0.0419, 0.0000, 0.0698, 0.0574, 0.1350, 0.0000,\n",
      "         0.0854, 0.0411, 0.0000, 0.1770, 0.0464, 0.1354, 0.0000, 0.0754, 0.0816,\n",
      "         0.0738, 0.1323, 0.2208, 0.2096, 0.0148, 0.0000, 0.1061, 0.0000, 0.2097,\n",
      "         0.0732, 0.1050, 0.0000, 0.0686, 0.0000, 0.2019, 0.0000, 0.0000, 0.1574,\n",
      "         0.0795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0584, 0.0790, 0.0086,\n",
      "         0.0000, 0.1523, 0.1471, 0.1013, 0.0000, 0.0000, 0.0000, 0.0554, 0.0000,\n",
      "         0.2861, 0.0000, 0.0000, 0.0000, 0.0380, 0.0000, 0.1652, 0.0000, 0.0569,\n",
      "         0.0000, 0.0050, 0.0000, 0.0000, 0.0000, 0.0068, 0.0044, 0.2033, 0.0000,\n",
      "         0.0000, 0.0777, 0.0473, 0.0000, 0.0133, 0.0000, 0.0108, 0.1567, 0.0000,\n",
      "         0.0371, 0.0000, 0.0000, 0.1152, 0.0632, 0.0000, 0.0000, 0.0108, 0.0981,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1466, 0.2511, 0.0000,\n",
      "         0.0000, 0.0000, 0.1153, 0.1251, 0.0000, 0.0988, 0.0000, 0.0000, 0.1147,\n",
      "         0.0000, 0.0305, 0.1876, 0.1811, 0.0109, 0.0000, 0.0716, 0.0857, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "torch.manual_seed(42) \n",
    "img = torch.randn(3, 2, 200, 50)  \n",
    "encoder = CnnEncoder(2,200,50,256)\n",
    "# print(img)\n",
    "output = encoder.forward(img)  \n",
    "print(\"Output shape:\", output)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
